{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from dataset import NewsDataset\n",
    "from DistilbertModel import DistilBertForSequenceClassification\n",
    "\n",
    "from smooth_gradient import SmoothGradient\n",
    "from integrated_gradient import IntegratedGradient\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertConfig, DistilBertTokenizer\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistilBertConfig()\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# distilbert = DistilBertForSequenceClassification(config, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert = DistilBertForSequenceClassification(config=config)#.from_pretrained(None,config=config,state_dict='distilbert_cad_final1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './distilbert_cad_final1.pt'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    distilbert.load_state_dict(\n",
    "        torch.load(path)\n",
    "    )\n",
    "else:\n",
    "    distilbert.load_state_dict(\n",
    "        torch.load(path, map_location=torch.device('cpu'))\n",
    "    )\n",
    "    \n",
    "# # with open('../label_encoder.sklrn', 'rb') as f:\n",
    "# #     le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saliency_interpreter import SaliencyInterpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<saliency_interpreter.SaliencyInterpreter at 0x2aab2e4a2978>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SaliencyInterpreter(model=distilbert, criterion=criterion, tokenizer=tokenizer)._get_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilbert = DistilBertForSequenceClassification.from_pretrained('../tcav/bertcheckpoints/distilbert/distilbert_cad_final1.h5',output_attentions=True, from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([[0]*512]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions=distilbert(input_ids=torch.tensor([[0]*512]),return_dict=True,output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../tcav2/data/CAD_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(test_df['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.95s/it]\n",
      "100%|██████████| 1/1 [00:36<00:00, 36.02s/it]\n"
     ]
    }
   ],
   "source": [
    "all_instances = []\n",
    "texts=['Patient was a pleasant male in his early 40s who was given plavix and aspirin for CAD and required cabg', 'Patient is healthy']\n",
    "for text in texts:\n",
    "    test_example = [\n",
    "        [text], \n",
    "        [\"\"]\n",
    "    ]\n",
    "\n",
    "    test_dataset = NewsDataset(\n",
    "        data_list=test_example,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=config.max_position_embeddings, \n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    integrated_grad = IntegratedGradient(\n",
    "        distilbert, \n",
    "        criterion, \n",
    "        tokenizer, \n",
    "        show_progress=True,\n",
    "        encoder=\"bert\"\n",
    "    )\n",
    "    instances = integrated_grad.saliency_interpret(test_dataloader)\n",
    "    all_instances.append(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"barcode\"; style=\"color: black; background-color: #e3eef9\"> [CLS]</span><span class=\"barcode\"; style=\"color: black; background-color: #f7fbff\"> patient</span><span class=\"barcode\"; style=\"color: black; background-color: #f1f7fd\"> is</span><span class=\"barcode\"; style=\"color: black; background-color: #ccdff1\"> healthy</span><span class=\"barcode\"; style=\"color: black; background-color: #08306b\"> [SEP]</span><span class=\"barcode\"; style=\"color: black; background-color: #1562a9\"> [SEP]</span><span class=\"barcode\"; style=\"color: black; background-color: 0\">    Label: 1 |</span><span class=\"barcode\"; style=\"color: black; background-color: #5db96b\">55.77%</span>|"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coloder_string = integrated_grad.colorize(instances[0])\n",
    "display(HTML(coloder_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_df = pd.DataFrame([instance[0] for instance in all_instances])#.to_csv('all_test_grads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel(lst):\n",
    "    return [i for j in lst for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# grads_df = pd.read_csv('all_test_grads2.csv')\n",
    "grads_df = pd.read_csv('all_train_grads2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_df['tokens']=grads_df['tokens'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_df['grad'] = grads_df['grad'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_grads = pd.DataFrame(  list(zip( unravel(grads_df[grads_df['label']==1]['tokens']),  unravel(grads_df[grads_df['label']==1]['grad']) )) , columns=['tokens', 'grad']  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_negative_grads = pd.DataFrame(  list(zip( unravel(grads_df[grads_df['label']==0]['tokens']),  unravel(grads_df[grads_df['label']==0]['grad']) )) , columns=['tokens', 'grad']  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_negative_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word =''\n",
    "score=0\n",
    "words=[]\n",
    "scores=[]\n",
    "for i in reversed(range(len(all_positive_grads))):\n",
    "    token=all_positive_grads['tokens'].iloc[i]\n",
    "    if token.startswith('##'):\n",
    "        word = token[2:]+word\n",
    "        score = max(score,all_positive_grads['grad'].iloc[i] )\n",
    "#         print(word)\n",
    "    else:\n",
    "        word = token+word\n",
    "#         print(word)\n",
    "        words.append(word)\n",
    "        score = max(score,all_positive_grads['grad'].iloc[i] )\n",
    "        scores.append(score)\n",
    "        word=''\n",
    "        score=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "           word &  grad\\_mean &  word\\_count \\\\\n",
      "\\midrule\n",
      "         cabgx1 &      0.127 &          14 \\\\\n",
      "         cabgx3 &      0.110 &          45 \\\\\n",
      "         cabgx5 &      0.107 &           7 \\\\\n",
      "         cabgx4 &      0.094 &          41 \\\\\n",
      "         cabgx2 &      0.086 &          21 \\\\\n",
      "           cabg &      0.083 &        2210 \\\\\n",
      "          [SEP] &      0.067 &        9364 \\\\\n",
      "            cad &      0.063 &        1344 \\\\\n",
      " bronchodilator &      0.054 &           6 \\\\\n",
      "            rca &      0.052 &         655 \\\\\n",
      "         artery &      0.039 &         703 \\\\\n",
      "     integrelin &      0.035 &         105 \\\\\n",
      "           simv &      0.034 &         351 \\\\\n",
      "     fasciotomy &      0.033 &           6 \\\\\n",
      "          wires &      0.030 &        1200 \\\\\n",
      "           pvcs &      0.029 &         310 \\\\\n",
      "            lad &      0.028 &         981 \\\\\n",
      "    thoracotomy &      0.028 &          31 \\\\\n",
      "            ace &      0.027 &         365 \\\\\n",
      "        insulin &      0.027 &        2962 \\\\\n",
      "            pvc &      0.027 &        1071 \\\\\n",
      "          pmicu &      0.027 &          23 \\\\\n",
      "        nailbed &      0.027 &           6 \\\\\n",
      "      maneuvers &      0.026 &           6 \\\\\n",
      "            lbp &      0.026 &           6 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_grouped = pd.DataFrame(list(zip(words, scores)), columns=['words', 'grad']).groupby('words')\n",
    "means = tokens_grouped['grad'].mean()\n",
    "cts = tokens_grouped['grad'].count()\n",
    "wrds = tokens_grouped.apply(lambda group: str(group.name))\n",
    "positive_df = pd.DataFrame(list(zip(wrds,means,cts)), columns=['word','grad_mean','word_count' ]).sort_values(by='grad_mean',ascending=False)\n",
    "positive_df = positive_df[positive_df['word_count']>5]\n",
    "print(positive_df.head(25).to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word =''\n",
    "score=0\n",
    "negative_words=[]\n",
    "negative_scores=[]\n",
    "for i in reversed(range(len(all_negative_grads))):\n",
    "    token=all_negative_grads['tokens'].iloc[i]\n",
    "    if token.startswith('##'):\n",
    "        word = token[2:]+word\n",
    "        score = max(score,all_negative_grads['grad'].iloc[i] )\n",
    "#         print(word)\n",
    "    else:\n",
    "        word = token+word\n",
    "#         print(word)\n",
    "        negative_words.append(word)\n",
    "        score = max(score,all_negative_grads['grad'].iloc[i] )\n",
    "        negative_scores.append(score)\n",
    "        word=''\n",
    "        score=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "                word &  grad\\_mean &  word\\_count \\\\\n",
      "\\midrule\n",
      "                 cad &      0.094 &          76 \\\\\n",
      "               [SEP] &      0.081 &        6819 \\\\\n",
      "                 lad &      0.075 &           7 \\\\\n",
      "           narrative &      0.069 &          37 \\\\\n",
      "                cabg &      0.068 &          10 \\\\\n",
      "                 npn &      0.064 &         762 \\\\\n",
      "           cadaveric &      0.057 &           7 \\\\\n",
      "                 pvc &      0.047 &         480 \\\\\n",
      "                pvcs &      0.042 &         166 \\\\\n",
      "                 ccu &      0.040 &         306 \\\\\n",
      "                simv &      0.037 &          72 \\\\\n",
      "         prostectomy &      0.036 &           6 \\\\\n",
      "         thorocotomy &      0.036 &           6 \\\\\n",
      "              pedial &      0.035 &          20 \\\\\n",
      "               tsicu &      0.035 &         516 \\\\\n",
      "   gastrojejunostomy &      0.033 &           7 \\\\\n",
      "           lobectomy &      0.032 &          65 \\\\\n",
      "                sicu &      0.032 &        1475 \\\\\n",
      " esophagogastrectomy &      0.032 &          19 \\\\\n",
      "                 pvd &      0.032 &          78 \\\\\n",
      "                csru &      0.031 &          58 \\\\\n",
      "               msicu &      0.030 &          16 \\\\\n",
      "                cart &      0.030 &          11 \\\\\n",
      "        thrombectomy &      0.029 &          16 \\\\\n",
      "        annuloplasty &      0.029 &           9 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_grouped = pd.DataFrame(list(zip(negative_words, negative_scores)), columns=['words', 'grad']).groupby('words')\n",
    "means = tokens_grouped['grad'].mean()\n",
    "cts = tokens_grouped['grad'].count()\n",
    "wrds = tokens_grouped.apply(lambda group: str(group.name))\n",
    "negative_df = pd.DataFrame(list(zip(wrds,means,cts)), columns=['word','grad_mean','word_count' ]).sort_values(by='grad_mean',ascending=False)\n",
    "negative_df = negative_df[negative_df['word_count']>5]\n",
    "print(negative_df.head(25).to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grad']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'</td>\n",
       "      <td>0.028707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>0.051793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>0.001401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>0.005617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117397</th>\n",
       "      <td>L</td>\n",
       "      <td>0.007958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117398</th>\n",
       "      <td>C</td>\n",
       "      <td>0.003365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117399</th>\n",
       "      <td>[</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117400</th>\n",
       "      <td>'</td>\n",
       "      <td>0.005063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117401</th>\n",
       "      <td>[</td>\n",
       "      <td>0.007274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117402 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       words      grad\n",
       "0          '  0.028707\n",
       "1          a  0.051793\n",
       "2          i  0.001401\n",
       "3          s  0.000330\n",
       "4          e  0.005617\n",
       "...      ...       ...\n",
       "117397     L  0.007958\n",
       "117398     C  0.003365\n",
       "117399     [  0.001415\n",
       "117400     '  0.005063\n",
       "117401     [  0.007274\n",
       "\n",
       "[117402 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(words, scores)), columns=['words', 'grad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d62e443bf3c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grad'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(zip(instances[0]['tokens'], instances[0]['grad'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tokens': ['[CLS]',\n",
       "   \"'\",\n",
       "   'patient',\n",
       "   'was',\n",
       "   'a',\n",
       "   'pleasant',\n",
       "   'male',\n",
       "   'in',\n",
       "   'his',\n",
       "   'early',\n",
       "   '40',\n",
       "   '##s',\n",
       "   'who',\n",
       "   'was',\n",
       "   'given',\n",
       "   'pl',\n",
       "   '##avi',\n",
       "   '##x',\n",
       "   'and',\n",
       "   'as',\n",
       "   '##pi',\n",
       "   '##rin',\n",
       "   'for',\n",
       "   'cad',\n",
       "   'and',\n",
       "   'required',\n",
       "   'cab',\n",
       "   '##g',\n",
       "   \"'\",\n",
       "   '[SEP]',\n",
       "   'transform',\n",
       "   '##er',\n",
       "   '-',\n",
       "   'based',\n",
       "   'models',\n",
       "   'have',\n",
       "   'taken',\n",
       "   'a',\n",
       "   'leading',\n",
       "   'role',\n",
       "   'in',\n",
       "   'nl',\n",
       "   '##p',\n",
       "   'today',\n",
       "   '.',\n",
       "   '[SEP]'],\n",
       "  'grad': [0.0024040760472416878,\n",
       "   0.011202486231923103,\n",
       "   0.013759119436144829,\n",
       "   0.002332319738343358,\n",
       "   0.011373970657587051,\n",
       "   0.02735648676753044,\n",
       "   0.015535157173871994,\n",
       "   0.030777039006352425,\n",
       "   0.008332711644470692,\n",
       "   0.013340604491531849,\n",
       "   0.0001066805562004447,\n",
       "   0.0027349493466317654,\n",
       "   0.004292184952646494,\n",
       "   0.00442542415112257,\n",
       "   0.007150531280785799,\n",
       "   0.0028611449524760246,\n",
       "   0.015010221861302853,\n",
       "   0.018782952800393105,\n",
       "   0.01669878326356411,\n",
       "   0.009789077565073967,\n",
       "   0.016139263287186623,\n",
       "   0.007285908330231905,\n",
       "   0.0340462364256382,\n",
       "   0.0994633287191391,\n",
       "   0.02390855737030506,\n",
       "   0.01794828474521637,\n",
       "   0.17008531093597412,\n",
       "   0.12981343269348145,\n",
       "   0.021933887153863907,\n",
       "   0.1389886736869812,\n",
       "   0.020783530548214912,\n",
       "   0.0065027992241084576,\n",
       "   0.008362825959920883,\n",
       "   0.0033463663421571255,\n",
       "   0.003560791490599513,\n",
       "   0.0011002038372680545,\n",
       "   0.00035022245720028877,\n",
       "   0.020194558426737785,\n",
       "   0.002988012507557869,\n",
       "   0.0009293951443396509,\n",
       "   0.0005665147327817976,\n",
       "   0.004190972540527582,\n",
       "   0.004393792245537043,\n",
       "   0.003207903355360031,\n",
       "   0.003286235500127077,\n",
       "   0.03835707902908325],\n",
       "  'label': 1,\n",
       "  'prob': 0.985454797744751}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
